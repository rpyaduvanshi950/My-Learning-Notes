
| Algorithm                   | Description                                                  | Key Steps                                                                                                            | Pros                                                              | Cons                                                          |                                                                                |                                                          |                                                             |
| --------------------------- | ------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- | ------------------------------------------------------------- | ------------------------------------------------------------------------------ | -------------------------------------------------------- | ----------------------------------------------------------- |
| **Grid Approximation**      | Discretize parameter space and compute posterior exactly     | 1. Define a grid of Œ∏ values<br>2. Compute likelihood √ó prior at each point<br>3. Normalize to get posterior density | + Conceptually simple<br>+ Exact (on grid)                        | ‚Äì Curse of dimensionality<br>‚Äì Poor resolution if grid coarse |                                                                                |                                                          |                                                             |
| **Monte Carlo Integration** | Estimate integrals (e.g. marginal likelihood) by averaging   | 1. Draw Œ∏·µ¢ ‚àº prior<br>2. Compute p(y                                                                                 | Œ∏·µ¢)<br>3. Average those likelihoods                               | + Easy to implement<br>+ No proposal tuning                   | ‚Äì Doesn‚Äôt give posterior samples<br>‚Äì Inefficient if prior‚â†posterior           |                                                          |                                                             |
| **Rejection Sampling**      | Generate independent samples from posterior by accept/reject | 1. Draw Œ∏\* ‚àº proposal g(Œ∏)<br>2. Compute score = p(y                                                                | Œ∏\*) p(Œ∏\*) / \[M g(Œ∏\*)]<br>3. Draw u‚àºU(0,1); accept if u\<score | + Simple conceptually<br>+ True independent samples           | ‚Äì High rejection rate<br>‚Äì Needs good bound M<br>‚Äì Scales poorly               |                                                          |                                                             |
| **Metropolis‚ÄìHastings**     | MCMC via random-walk proposals and accept/reject             | 1. Initialize Œ∏‚ÇÄ<br>2. Propose Œ∏\* ‚àº q(¬∑                                                                             | Œ∏·µ¢)<br>3. Compute H = \[p(y                                       | Œ∏\*)p(Œ∏\*)] / \[p(y                                           | Œ∏·µ¢)p(Œ∏·µ¢)]<br>4. Accept with prob min(1,H), else stay                           | + Works in high dimension<br>+ No need for normalization | ‚Äì Samples correlated<br>‚Äì Requires tuning of proposal scale |
| **Gibbs Sampling**          | MCMC by sampling each parameter from its conditional         | 1. Initialize all Œ∏‚Äôs<br>2. For each parameter j:<br>‚ÄÇ‚ÄÇŒ∏‚±º ‚àº p(Œ∏‚±º                                                     | all other Œ∏‚Äôs, y)<br>3. Repeat for N iterations                   | + No reject step<br>+ Efficient if conditionals known         | ‚Äì Requires closed-form conditionals<br>‚Äì Can mix slowly if strong dependencies |                                                          |                                                             |

---

## üîÅ Summary of Use-Cases

| **If you want to...**                                        | **Use this algorithm**     |
| ------------------------------------------------------------ | -------------------------- |
| Estimate marginal likelihood or expectation                  | Monte Carlo Integration    |
| Get independent posterior samples (low dim)                  | Rejection Sampling         |
| Sample from complex posterior (general-purpose)              | Metropolis‚ÄìHastings (MCMC) |
| Sample from posterior with easy conditionals (multi-variate) | Gibbs Sampling             |

---
